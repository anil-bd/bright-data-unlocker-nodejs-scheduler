name: Daily Scrape

on:
  schedule:
    - cron: '0 0 * * *' # Runs every day at midnight UTC
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: npm install

      - name: Create .env file from secrets
        run: |
          echo "BRIGHT_DATA_API_TOKEN=${{ secrets.BRIGHT_DATA_API_TOKEN }}" >> .env
          echo "BRIGHT_DATA_ZONE=${{ secrets.BRIGHT_DATA_ZONE }}" >> .env

      - name: Run scraper
        run: node index.js

      - name: Commit and push scraping output
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add scraping-output/
          git commit -m "Update scraping output [skip ci]" || echo "No changes to commit"
          git push 